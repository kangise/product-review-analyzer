#!/usr/bin/env python3
"""
è¿è¡Œå®Œæ•´çš„è¯„è®ºåˆ†æç®¡é“ - å¸¦æœ‰å®æ—¶è¿›åº¦è·Ÿè¸ª
"""

import sys
import os
import json
import logging
import re
import subprocess
from pathlib import Path
from typing import Dict, Any
from review_analyzer import ReviewAnalyzer
import time

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# åˆ†ææ­¥éª¤å®šä¹‰ - ä¸å®é™…çš„åˆ†ææµç¨‹å¯¹åº”
ANALYSIS_STEPS = [
    {"id": "product_type", "name": "Product Classification", "name_zh": "äº§å“åˆ†ç±»åˆ†æ"},
    {"id": "consumer_profile", "name": "Consumer Profile Analysis", "name_zh": "æ¶ˆè´¹è€…ç”»åƒåˆ†æ"},
    {"id": "consumer_scenario", "name": "Usage Scenario Analysis", "name_zh": "ä½¿ç”¨åœºæ™¯åˆ†æ"},
    {"id": "consumer_motivation", "name": "Purchase Motivation Analysis", "name_zh": "è´­ä¹°åŠ¨æœºåˆ†æ"},
    {"id": "consumer_love", "name": "Customer Satisfaction Analysis", "name_zh": "å®¢æˆ·æ»¡æ„åº¦åˆ†æ"},
    {"id": "unmet_needs", "name": "Unmet Needs Analysis", "name_zh": "æœªæ»¡è¶³éœ€æ±‚åˆ†æ"},
    {"id": "opportunity", "name": "Business Opportunity Analysis", "name_zh": "å•†ä¸šæœºä¼šåˆ†æ"},
    {"id": "star_rating_root_cause", "name": "Rating Root Cause Analysis", "name_zh": "è¯„åˆ†æ ¹å› åˆ†æ"},
    {"id": "competitor", "name": "Competitive Analysis", "name_zh": "ç«äº‰åˆ†æ"}
]

def output_progress(step_index, status, message=""):
    """è¾“å‡ºè¿›åº¦ä¿¡æ¯åˆ°stdoutï¼Œä¾›APIæœåŠ¡å™¨è§£æ"""
    progress_data = {
        "step_index": step_index,
        "total_steps": len(ANALYSIS_STEPS),
        "progress": int((step_index / len(ANALYSIS_STEPS)) * 90) + 5,  # 5-95%
        "status": status,
        "current_step": ANALYSIS_STEPS[step_index] if step_index < len(ANALYSIS_STEPS) else None,
        "message": message,
        "timestamp": time.time()
    }
    
    # è¾“å‡ºJSONæ ¼å¼çš„è¿›åº¦ä¿¡æ¯ï¼Œå‰ç¼€PROGRESS:ä¾¿äºAPIæœåŠ¡å™¨è§£æ
    print(f"PROGRESS:{json.dumps(progress_data)}", flush=True)

class ProgressTrackingAnalyzer(ReviewAnalyzer):
    """å¸¦æœ‰è¿›åº¦è·Ÿè¸ªçš„åˆ†æå™¨"""
    
    def run_analysis_pipeline_with_progress(self, customer_review_path: str, competitor_review_path: str, product_type: str):
        """è¿è¡Œå¸¦æœ‰è¿›åº¦è·Ÿè¸ªçš„åˆ†æç®¡é“"""
        
        output_progress(0, "starting", "Initializing analysis pipeline...")
        logger.info("å¼€å§‹è¿è¡Œåˆ†æç®¡é“...")
        
        # 1. æ•°æ®æ¸…ç†
        output_progress(0, "running", "Loading and cleaning data...")
        self.load_and_clean_data(customer_review_path, competitor_review_path)
        
        # 2. äº§å“ç±»å‹åˆ†æ
        output_progress(0, "running", "Analyzing product type...")
        logger.info("æ­¥éª¤1: äº§å“ç±»å‹åˆ†æ")
        product_type_prompt = self.load_prompt('product_type.md')
        self.results['product_type'] = self.call_q_chat(
            product_type_prompt, 
            {'product_type': product_type}
        )
        # ä¿å­˜ç¬¬ä¸€æ­¥ç»“æœ
        step_file = self.output_dir / "product_type.json"
        with open(step_file, 'w', encoding='utf-8') as f:
            json.dump(self.results['product_type'], f, indent=2, ensure_ascii=False)
        logger.info(f"æ­¥éª¤1ç»“æœå·²ä¿å­˜: {step_file}")
        output_progress(0, "completed", "Product type analysis completed")
        
        # æå–ç¬¬ä¸€æ­¥çš„å¹²å‡€ç»“æœç”¨äºåç»­æ­¥éª¤
        clean_product_type = self.extract_clean_result(self.results['product_type'])
        
        # 3. æ¶ˆè´¹è€…åˆ†æ (5ä¸ªæ­¥éª¤)
        consumer_prompts = [
            ('consumer_profile.md', 1, "Consumer profile analysis"),
            ('consumer_scenario.md', 2, "Usage scenario analysis"), 
            ('consumer_motivation.md', 3, "Purchase motivation analysis"),
            ('consumer_love.md', 4, "Customer satisfaction analysis"),
            ('unmet_needs.md', 5, "Unmet needs analysis")
        ]
        
        logger.info("æ­¥éª¤2: æ¶ˆè´¹è€…åˆ†æ")
        for prompt_file, step_idx, step_desc in consumer_prompts:
            output_progress(step_idx, "running", f"Executing {step_desc}...")
            
            prompt_name = prompt_file.replace('.md', '')
            logger.info(f"  æ‰§è¡Œ: {prompt_name}")
            
            prompt = self.load_prompt(prompt_file)
            
            # ä¸ºæ¯ä¸ªæ¶ˆè´¹è€…åˆ†ææä¾›ç›¸åº”çš„ä¸Šä¸‹æ–‡
            context = {
                'product_type': clean_product_type if clean_product_type else product_type,
                'customer_review_data': self.cleaned_data['customer_review']
            }
            
            # ä¼˜åŒ–ä¸Šä¸‹æ–‡æ•°æ®
            optimized_context = self.prepare_context_data(context)
            self.results[prompt_name] = self.call_q_chat(prompt, optimized_context)
            
            # ä¿å­˜æ¯ä¸ªæ¶ˆè´¹è€…åˆ†ææ­¥éª¤çš„ç»“æœ
            step_file = self.output_dir / f"{prompt_name}.json"
            with open(step_file, 'w', encoding='utf-8') as f:
                json.dump(self.results[prompt_name], f, indent=2, ensure_ascii=False)
            logger.info(f"æ­¥éª¤2.{prompt_name}ç»“æœå·²ä¿å­˜: {step_file}")
            output_progress(step_idx, "completed", f"{step_desc} completed")
        
        # 4. æœºä¼šåˆ†æ
        output_progress(6, "running", "Analyzing business opportunities...")
        logger.info("æ­¥éª¤3: æœºä¼šåˆ†æ")
        opportunity_prompt = self.load_prompt('opportunity.md')
        
        # æå–å¹²å‡€çš„åˆ†æç»“æœç”¨äºå‚æ•°ä¼ é€’
        clean_consumer_love = self.extract_clean_result(self.results['consumer_love'])
        clean_unmet_needs = self.extract_clean_result(self.results['unmet_needs'])
        clean_consumer_scenario = self.extract_clean_result(self.results['consumer_scenario'])
        
        opportunity_context = {
            'product_type': clean_product_type if clean_product_type else product_type,
            'consumer_love': clean_consumer_love if clean_consumer_love else "[æ¶ˆè´¹è€…å–œçˆ±ç‚¹åˆ†æä¸å¯ç”¨]",
            'unmet_needs': clean_unmet_needs if clean_unmet_needs else "[æœªæ»¡è¶³éœ€æ±‚åˆ†æä¸å¯ç”¨]",
            'consumer_scenario': clean_consumer_scenario if clean_consumer_scenario else "[ä½¿ç”¨åœºæ™¯åˆ†æä¸å¯ç”¨]",
            'customer_review_data': self.cleaned_data['customer_review']
        }
        self.results['opportunity'] = self.call_q_chat(opportunity_prompt, self.prepare_context_data(opportunity_context))
        # ä¿å­˜æœºä¼šåˆ†æç»“æœ
        step_file = self.output_dir / "opportunity.json"
        with open(step_file, 'w', encoding='utf-8') as f:
            json.dump(self.results['opportunity'], f, indent=2, ensure_ascii=False)
        logger.info(f"æ­¥éª¤3ç»“æœå·²ä¿å­˜: {step_file}")
        output_progress(6, "completed", "Business opportunity analysis completed")
        
        # 5. æ˜Ÿçº§è¯„åˆ†æ ¹å› åˆ†æ
        output_progress(7, "running", "Analyzing rating root causes...")
        logger.info("æ­¥éª¤4: æ˜Ÿçº§è¯„åˆ†æ ¹å› åˆ†æ")
        star_rating_prompt = self.load_prompt('star_rating_root_cause.md')
        # æå–å…·ä½“çš„å–œçˆ±ç‚¹å’Œæœªæ»¡è¶³éœ€æ±‚åˆ—è¡¨
        love_points = []
        unmet_needs_list = []
        
        if clean_consumer_love:
            love_points = [item["èµç¾ç‚¹"] for item in clean_consumer_love.get("æ ¸å¿ƒèµç¾ç‚¹åˆ†æ", [])]
        
        if clean_unmet_needs:
            unmet_needs_list = [item["ç—›ç‚¹/æœªæ»¡è¶³çš„éœ€æ±‚"] for item in clean_unmet_needs.get("æœªæ»¡è¶³éœ€æ±‚åˆ†æ", [])]
        
        star_rating_context = {
            'product_type': clean_product_type if clean_product_type else product_type,
            'consumer_love_points': love_points,
            'unmet_needs_list': unmet_needs_list,
            'customer_review_data': self.cleaned_data['customer_review']
        }
        self.results['star_rating_root_cause'] = self.call_q_chat(star_rating_prompt, self.prepare_context_data(star_rating_context))
        # ä¿å­˜æ˜Ÿçº§è¯„åˆ†åˆ†æç»“æœ
        step_file = self.output_dir / "star_rating_root_cause.json"
        with open(step_file, 'w', encoding='utf-8') as f:
            json.dump(self.results['star_rating_root_cause'], f, indent=2, ensure_ascii=False)
        logger.info(f"æ­¥éª¤4ç»“æœå·²ä¿å­˜: {step_file}")
        output_progress(8, "completed", "Rating root cause analysis completed")
        
        # 6. ç«äº‰å¯¹æ‰‹åˆ†æ (æ–°çš„ä¸‰é˜¶æ®µæµç¨‹)
        output_progress(8, "running", "Analyzing competitor data...")
        logger.info("æ­¥éª¤5: ç«äº‰å¯¹æ‰‹åˆ†æ")
        
        # æå–æˆ‘æ–¹ç»´åº¦æ¸…å•
        clean_consumer_love = self.extract_clean_result(self.results['consumer_love'])
        clean_unmet_needs = self.extract_clean_result(self.results['unmet_needs'])
        clean_consumer_motivation = self.extract_clean_result(self.results['consumer_motivation'])
        
        if clean_consumer_love or clean_unmet_needs or clean_consumer_motivation:
            # æå–ç»´åº¦åˆ—è¡¨ï¼ˆåªä»æˆåŠŸçš„æ¨¡å—ä¸­æå–ï¼‰
            our_love_dimensions = []
            our_unmet_dimensions = []
            our_motivation_dimensions = []
            
            if clean_consumer_love:
                our_love_dimensions = [item["èµç¾ç‚¹"] for item in clean_consumer_love.get("æ ¸å¿ƒèµç¾ç‚¹åˆ†æ", [])]
            if clean_unmet_needs:
                our_unmet_dimensions = [item["ç—›ç‚¹/æœªæ»¡è¶³çš„éœ€æ±‚"] for item in clean_unmet_needs.get("æœªæ»¡è¶³éœ€æ±‚åˆ†æ", [])]
            if clean_consumer_motivation:
                our_motivation_dimensions = [item["åŠ¨æœº"] for item in clean_consumer_motivation.get("å…·ä½“è´­ä¹°åŠ¨æœº", [])]
            
            logger.info(f"  æå–ç»´åº¦: å–œçˆ±ç‚¹{len(our_love_dimensions)}ä¸ª, æœªæ»¡è¶³éœ€æ±‚{len(our_unmet_dimensions)}ä¸ª, è´­ä¹°åŠ¨æœº{len(our_motivation_dimensions)}ä¸ª")
            
            # é˜¶æ®µ1: ç«å“åŸºç¡€åˆ†æ
            logger.info("  é˜¶æ®µ1: ç«å“åŸºç¡€åˆ†æ")
            competitor_base_prompt = self.load_prompt('competitor_analysis_base.md')
            
            competitor_base_context = {
                'our_love_dimensions': our_love_dimensions,
                'our_unmet_dimensions': our_unmet_dimensions,
                'our_motivation_dimensions': our_motivation_dimensions,
                'competitor_review_data': self.cleaned_data['competitor_review']
            }
            self.results['competitor_base'] = self.call_q_chat(competitor_base_prompt, self.prepare_context_data(competitor_base_context))
            
            # ä¿å­˜ç«å“åŸºç¡€åˆ†æç»“æœ
            step_file = self.output_dir / "competitor_base.json"
            with open(step_file, 'w', encoding='utf-8') as f:
                json.dump(self.results['competitor_base'], f, indent=2, ensure_ascii=False)
            logger.info(f"  é˜¶æ®µ1ç»“æœå·²ä¿å­˜: {step_file}")
            
            # é˜¶æ®µ2: ç«å“å¯¹æ¯”åˆ†æ
            logger.info("  é˜¶æ®µ2: ç«å“å¯¹æ¯”åˆ†æ")
            clean_competitor_base = self.extract_clean_result(self.results['competitor_base'])
            
            if clean_competitor_base:
                competitor_comparison_prompt = self.load_prompt('competitor_comparison.md')
                competitor_comparison_context = {
                    'our_consumer_love': clean_consumer_love or {"æ ¸å¿ƒèµç¾ç‚¹åˆ†æ": []},
                    'our_unmet_needs': clean_unmet_needs or {"æœªæ»¡è¶³éœ€æ±‚åˆ†æ": []},
                    'our_consumer_motivation': clean_consumer_motivation or {"å…·ä½“è´­ä¹°åŠ¨æœº": []},
                    'competitor_consumer_love': clean_competitor_base.get('ç«å“æ¶ˆè´¹è€…å–œçˆ±ç‚¹', []),
                    'competitor_unmet_needs': clean_competitor_base.get('ç«å“æœªæ»¡è¶³éœ€æ±‚', []),
                    'competitor_consumer_motivation': clean_competitor_base.get('ç«å“è´­ä¹°åŠ¨æœº', [])
                }
                self.results['competitor_comparison'] = self.call_q_chat(competitor_comparison_prompt, self.prepare_context_data(competitor_comparison_context))
                
                # ä¿å­˜ç«å“å¯¹æ¯”åˆ†æç»“æœ
                step_file = self.output_dir / "competitor_comparison.json"
                with open(step_file, 'w', encoding='utf-8') as f:
                    json.dump(self.results['competitor_comparison'], f, indent=2, ensure_ascii=False)
                logger.info(f"  é˜¶æ®µ2ç»“æœå·²ä¿å­˜: {step_file}")
            else:
                logger.warning("  ç«å“åŸºç¡€åˆ†æå¤±è´¥ï¼Œè·³è¿‡å¯¹æ¯”åˆ†æ")
                self.results['competitor_comparison'] = {"error": "ç«å“åŸºç¡€åˆ†æå¤±è´¥"}
            
            # é˜¶æ®µ3: ç«å“ç‹¬æœ‰æ´å¯Ÿ
            logger.info("  é˜¶æ®µ3: ç«å“ç‹¬æœ‰æ´å¯Ÿ")
            competitor_unique_prompt = self.load_prompt('competitor_unique_insights.md')
            all_our_dimensions = our_love_dimensions + our_unmet_dimensions + our_motivation_dimensions
            competitor_unique_context = {
                'competitor_review_data': self.cleaned_data['competitor_review'],
                'our_analyzed_dimensions': all_our_dimensions
            }
            self.results['competitor_unique'] = self.call_q_chat(competitor_unique_prompt, self.prepare_context_data(competitor_unique_context))
            
            # ä¿å­˜ç«å“ç‹¬æœ‰æ´å¯Ÿç»“æœ
            step_file = self.output_dir / "competitor_unique.json"
            with open(step_file, 'w', encoding='utf-8') as f:
                json.dump(self.results['competitor_unique'], f, indent=2, ensure_ascii=False)
            logger.info(f"  é˜¶æ®µ3ç»“æœå·²ä¿å­˜: {step_file}")
            
            # åˆå¹¶æœ€ç»ˆç«å“åˆ†æç»“æœ
            final_competitor_result = {
                "ç«å“åŸºç¡€åˆ†æ": clean_competitor_base if clean_competitor_base else {"error": "åˆ†æå¤±è´¥"},
                "ç«å“å¯¹æ¯”åˆ†æ": self.extract_clean_result(self.results['competitor_comparison']) or {"error": "åˆ†æå¤±è´¥"},
                "ç«å“ç‹¬æœ‰æ´å¯Ÿ": self.extract_clean_result(self.results['competitor_unique']) or {"error": "åˆ†æå¤±è´¥"}
            }
            self.results['competitor'] = final_competitor_result
            
        else:
            logger.warning("æˆ‘æ–¹åŸºç¡€åˆ†æå…¨éƒ¨å¤±è´¥ï¼Œè·³è¿‡ç«å“åˆ†æ")
            self.results['competitor'] = {"error": "æˆ‘æ–¹åŸºç¡€åˆ†æå…¨éƒ¨å¤±è´¥ï¼Œæ— æ³•è¿›è¡Œç«å“å¯¹æ¯”"}
        
        # ä¿å­˜æœ€ç»ˆç«å“åˆ†æç»“æœ
        step_file = self.output_dir / "competitor.json"
        with open(step_file, 'w', encoding='utf-8') as f:
            json.dump(self.results['competitor'], f, indent=2, ensure_ascii=False)
        logger.info(f"æ­¥éª¤5ç»“æœå·²ä¿å­˜: {step_file}")
        output_progress(8, "completed", "Competitor analysis completed")
        
        # å®Œæˆæ‰€æœ‰åˆ†æ
        output_progress(len(ANALYSIS_STEPS), "completed", "All analysis steps completed successfully")
        logger.info("åˆ†æç®¡é“å®Œæˆ!")
        
        return self.results

def main():
    """è¿è¡Œåˆ†æç®¡é“"""
    logger.info("ğŸš€ å¼€å§‹è¿è¡Œè¯„è®ºåˆ†æç®¡é“...")
    
    # ä½¿ç”¨ä¸Šä¼ çš„æ•°æ®æ–‡ä»¶
    customer_review_path = "data/Customer ASIN Reviews.csv"
    competitor_review_path = "data/Competitor ASIN Reviews.csv"
    product_type = sys.argv[1] if len(sys.argv) > 1 else "webcams"
    output_language = sys.argv[2] if len(sys.argv) > 2 else "en"
    
    # è¾“å‡ºåˆå§‹è¿›åº¦
    output_progress(0, "starting", "Initializing analysis pipeline...")
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not Path(customer_review_path).exists():
        logger.error(f"âŒ å®¢æˆ·è¯„è®ºæ–‡ä»¶ä¸å­˜åœ¨: {customer_review_path}")
        output_progress(0, "failed", f"Customer review file not found: {customer_review_path}")
        sys.exit(1)
    
    try:
        # åˆ›å»ºå¸¦è¿›åº¦è·Ÿè¸ªçš„åˆ†æå™¨å®ä¾‹
        analyzer = ProgressTrackingAnalyzer(output_language=output_language)
        
        # è¿è¡Œå®Œæ•´çš„åˆ†æç®¡é“
        logger.info("ğŸ“Š å¼€å§‹æ‰§è¡Œåˆ†æç®¡é“...")
        results = analyzer.run_analysis_pipeline_with_progress(
            customer_review_path, 
            competitor_review_path, 
            product_type
        )
        
        # ä¿å­˜æœ€ç»ˆç»“æœ
        output_file = analyzer.save_results()
        
        # ä¿å­˜åˆ†æå…ƒæ•°æ®
        import json
        from datetime import datetime
        metadata = {
            'target_category': product_type,
            'timestamp': datetime.now().isoformat(),
            'has_competitor_data': os.path.exists(competitor_review_path)
        }
        
        metadata_file = analyzer.output_dir / "metadata.json"
        with open(metadata_file, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, indent=2, ensure_ascii=False)
        
        # æ˜¾ç¤ºç»“æœæ‘˜è¦
        logger.info("\n" + "="*60)
        logger.info("ğŸ‰ åˆ†æå®Œæˆ!")
        logger.info(f"ğŸ“ ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
        logger.info("="*60)
        
    except KeyboardInterrupt:
        logger.info("\nâ¹ï¸  åˆ†æè¢«ç”¨æˆ·ä¸­æ–­")
        output_progress(0, "failed", "Analysis interrupted by user")
        sys.exit(1)
    except Exception as e:
        logger.error(f"âŒ åˆ†æå¤±è´¥: {str(e)}")
        output_progress(0, "failed", f"Analysis failed: {str(e)}")
        sys.exit(1)

if __name__ == "__main__":
    main()
