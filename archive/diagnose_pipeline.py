#!/usr/bin/env python3
"""
è¯Šæ–­åˆ†æç®¡é“ä¸­çš„é—®é¢˜
"""

import pandas as pd
import json
import logging
from pathlib import Path
from review_analyzer import ReviewAnalyzer

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def analyze_data_structure():
    """åˆ†ææ•°æ®ç»“æ„"""
    logger.info("ğŸ” åˆ†ææ•°æ®ç»“æ„...")
    
    # æ£€æŸ¥æ¸…ç†åçš„æ•°æ®
    customer_file = "data/cleaned/customer_reviews_cleaned.csv"
    competitor_file = "data/cleaned/competitor_reviews_cleaned.csv"
    
    try:
        customer_df = pd.read_csv(customer_file)
        competitor_df = pd.read_csv(competitor_file)
        
        logger.info(f"å®¢æˆ·è¯„è®ºæ•°æ®å½¢çŠ¶: {customer_df.shape}")
        logger.info(f"å®¢æˆ·è¯„è®ºåˆ—å: {list(customer_df.columns)}")
        logger.info(f"ç«äº‰å¯¹æ‰‹è¯„è®ºæ•°æ®å½¢çŠ¶: {competitor_df.shape}")
        logger.info(f"ç«äº‰å¯¹æ‰‹è¯„è®ºåˆ—å: {list(competitor_df.columns)}")
        
        # æ£€æŸ¥Review Textåˆ—
        if 'Review Text' in customer_df.columns:
            sample_review = customer_df['Review Text'].iloc[0]
            logger.info(f"å®¢æˆ·è¯„è®ºæ ·æœ¬é•¿åº¦: {len(sample_review)} å­—ç¬¦")
            logger.info(f"å®¢æˆ·è¯„è®ºæ ·æœ¬å‰200å­—ç¬¦: {sample_review[:200]}...")
        
        # æ£€æŸ¥æ•°æ®è½¬æ¢ä¸ºJSONåçš„å¤§å°
        customer_records = customer_df.to_dict('records')
        customer_json = json.dumps(customer_records[:5], indent=2, ensure_ascii=False)
        logger.info(f"å‰5æ¡å®¢æˆ·è¯„è®ºJSONå¤§å°: {len(customer_json)} å­—ç¬¦")
        
        return True
    except Exception as e:
        logger.error(f"æ•°æ®ç»“æ„åˆ†æå¤±è´¥: {str(e)}")
        return False

def analyze_prompt_expectations():
    """åˆ†æpromptæœŸæœ›çš„è¾“å…¥è¾“å‡ºæ ¼å¼"""
    logger.info("ğŸ” åˆ†æpromptæœŸæœ›...")
    
    analyzer = ReviewAnalyzer()
    
    # æ£€æŸ¥å‡ ä¸ªå…³é”®promptæ–‡ä»¶
    key_prompts = ['consumer_profile.md', 'consumer_love.md', 'opportunity.md']
    
    for prompt_file in key_prompts:
        try:
            prompt_content = analyzer.load_prompt(prompt_file)
            
            # æŸ¥æ‰¾JSONç›¸å…³çš„è¦æ±‚
            json_mentions = prompt_content.count('JSON') + prompt_content.count('json')
            brace_mentions = prompt_content.count('{') + prompt_content.count('}')
            
            logger.info(f"{prompt_file}:")
            logger.info(f"  - JSONæåŠæ¬¡æ•°: {json_mentions}")
            logger.info(f"  - å¤§æ‹¬å·æ•°é‡: {brace_mentions}")
            logger.info(f"  - æ–‡ä»¶é•¿åº¦: {len(prompt_content)} å­—ç¬¦")
            
            # æŸ¥æ‰¾è¾“å‡ºæ ¼å¼è¦æ±‚
            if '```json' in prompt_content.lower():
                logger.info(f"  - è¦æ±‚markdown JSONæ ¼å¼")
            if '"' in prompt_content and ':' in prompt_content:
                logger.info(f"  - åŒ…å«JSONç»“æ„ç¤ºä¾‹")
                
        except Exception as e:
            logger.error(f"åˆ†æ{prompt_file}å¤±è´¥: {str(e)}")

def test_data_serialization():
    """æµ‹è¯•æ•°æ®åºåˆ—åŒ–"""
    logger.info("ğŸ” æµ‹è¯•æ•°æ®åºåˆ—åŒ–...")
    
    try:
        analyzer = ReviewAnalyzer()
        cleaned_data = analyzer.load_and_clean_data(
            'data/cleaned/customer_reviews_cleaned.csv',
            'data/cleaned/competitor_reviews_cleaned.csv'
        )
        
        # æµ‹è¯•ä¸åŒçš„æ•°æ®å‡†å¤‡æ–¹æ³•
        context_data = {
            'product_type': 'webcams',
            'customer_review_data': cleaned_data['customer_review']
        }
        
        # æ–¹æ³•1: å®Œæ•´æ•°æ®
        optimized_full = analyzer.prepare_context_data(context_data)
        full_json = json.dumps(optimized_full, indent=2, ensure_ascii=False)
        logger.info(f"å®Œæ•´æ•°æ®JSONå¤§å°: {len(full_json)} å­—ç¬¦")
        
        # æ–¹æ³•2: é™åˆ¶æ•°æ®é‡
        limited_data = cleaned_data['customer_review'].head(10)
        context_limited = {
            'product_type': 'webcams',
            'customer_review_data': limited_data
        }
        optimized_limited = analyzer.prepare_context_data(context_limited)
        limited_json = json.dumps(optimized_limited, indent=2, ensure_ascii=False)
        logger.info(f"é™åˆ¶æ•°æ®JSONå¤§å°: {len(limited_json)} å­—ç¬¦")
        
        # æ–¹æ³•3: åªä¿ç•™å…³é”®å­—æ®µ
        key_columns = ['Review Text', 'Review Rating', 'Review Title']
        if all(col in cleaned_data['customer_review'].columns for col in key_columns):
            key_data = cleaned_data['customer_review'][key_columns].head(20)
            context_key = {
                'product_type': 'webcams',
                'customer_review_data': key_data
            }
            optimized_key = analyzer.prepare_context_data(context_key)
            key_json = json.dumps(optimized_key, indent=2, ensure_ascii=False)
            logger.info(f"å…³é”®å­—æ®µæ•°æ®JSONå¤§å°: {len(key_json)} å­—ç¬¦")
        
        return True
    except Exception as e:
        logger.error(f"æ•°æ®åºåˆ—åŒ–æµ‹è¯•å¤±è´¥: {str(e)}")
        return False

def test_json_extraction():
    """æµ‹è¯•JSONæå–é€»è¾‘"""
    logger.info("ğŸ” æµ‹è¯•JSONæå–é€»è¾‘...")
    
    # æ¨¡æ‹Ÿä¸åŒçš„Q Chatè¾“å‡ºæ ¼å¼
    test_outputs = [
        # æ ¼å¼1: çº¯JSON
        '{"test": "value", "number": 123}',
        
        # æ ¼å¼2: Markdownä»£ç å—
        '''è¿™æ˜¯åˆ†æç»“æœï¼š

```json
{
  "analysis": "result",
  "data": [1, 2, 3]
}
```

ä»¥ä¸Šæ˜¯å®Œæ•´åˆ†æã€‚''',
        
        # æ ¼å¼3: æ··åˆå†…å®¹
        '''æ ¹æ®åˆ†æï¼Œæˆ‘å‘ç°ä»¥ä¸‹ç»“æœï¼š

{
  "key_findings": "important data",
  "recommendations": ["item1", "item2"]
}

è¿™äº›å‘ç°å¾ˆé‡è¦ã€‚''',
        
        # æ ¼å¼4: å¤æ‚åµŒå¥—
        '''åˆ†ææŠ¥å‘Šï¼š

```json
{
  "consumer_profile": {
    "demographics": {
      "age_groups": [
        {
          "range": "25-35",
          "percentage": 45.2
        }
      ]
    }
  }
}
```'''
    ]
    
    analyzer = ReviewAnalyzer()
    
    for i, output in enumerate(test_outputs, 1):
        logger.info(f"æµ‹è¯•è¾“å‡ºæ ¼å¼ {i}:")
        extracted = analyzer.extract_json_from_output(output)
        if extracted:
            try:
                parsed = json.loads(extracted)
                logger.info(f"  âœ… æˆåŠŸæå–å¹¶è§£æJSON")
                logger.info(f"  ğŸ“Š æå–çš„JSON: {extracted[:100]}...")
            except json.JSONDecodeError as e:
                logger.error(f"  âŒ JSONè§£æå¤±è´¥: {str(e)}")
                logger.error(f"  ğŸ“„ æå–çš„å†…å®¹: {extracted[:200]}...")
        else:
            logger.error(f"  âŒ æœªèƒ½æå–JSON")

def analyze_parameter_flow():
    """åˆ†æå‚æ•°æµè½¬"""
    logger.info("ğŸ” åˆ†æå‚æ•°æµè½¬...")
    
    # æ£€æŸ¥æ¯ä¸ªæ­¥éª¤çš„å‚æ•°ä¾èµ–
    pipeline_steps = {
        'product_type': {
            'inputs': ['product_type'],
            'outputs': ['product_type_result']
        },
        'consumer_profile': {
            'inputs': ['product_type', 'customer_review_data'],
            'outputs': ['consumer_profile_result']
        },
        'consumer_love': {
            'inputs': ['product_type', 'customer_review_data'],
            'outputs': ['consumer_love_result']
        },
        'opportunity': {
            'inputs': ['product_type', 'consumer_love', 'unmet_needs', 'consumer_scenario', 'customer_review_data'],
            'outputs': ['opportunity_result']
        },
        'competitor': {
            'inputs': ['product_type', 'consumer_love', 'unmet_needs', 'consumer_motivation', 'customer_review_data', 'competitor_review_data'],
            'outputs': ['competitor_result']
        }
    }
    
    logger.info("å‚æ•°ä¾èµ–å…³ç³»:")
    for step, info in pipeline_steps.items():
        logger.info(f"  {step}:")
        logger.info(f"    è¾“å…¥: {info['inputs']}")
        logger.info(f"    è¾“å‡º: {info['outputs']}")
        
        # æ£€æŸ¥å¾ªç¯ä¾èµ–
        if step in info['inputs']:
            logger.error(f"    âš ï¸  å‘ç°å¾ªç¯ä¾èµ–: {step}")

def main():
    """ä¸»è¯Šæ–­å‡½æ•°"""
    logger.info("ğŸš€ å¼€å§‹è¯Šæ–­åˆ†æç®¡é“é—®é¢˜...")
    logger.info("=" * 60)
    
    tests = [
        ("æ•°æ®ç»“æ„åˆ†æ", analyze_data_structure),
        ("PromptæœŸæœ›åˆ†æ", analyze_prompt_expectations),
        ("æ•°æ®åºåˆ—åŒ–æµ‹è¯•", test_data_serialization),
        ("JSONæå–æµ‹è¯•", test_json_extraction),
        ("å‚æ•°æµè½¬åˆ†æ", analyze_parameter_flow)
    ]
    
    for test_name, test_func in tests:
        logger.info(f"\nğŸ“‹ {test_name}")
        logger.info("-" * 40)
        try:
            test_func()
        except Exception as e:
            logger.error(f"âŒ {test_name} å¼‚å¸¸: {str(e)}")
    
    logger.info("\n" + "=" * 60)
    logger.info("ğŸ è¯Šæ–­å®Œæˆ")

if __name__ == "__main__":
    main()
