#!/usr/bin/env python3
"""
Review Analyzer - AI Agent Pipeline (Fixed Version)
ä¿®å¤ç‰ˆæœ¬ï¼šè§£å†³å‰ç½®ä¾èµ–å’Œè¾“å‡ºè·¯å¾„ç»Ÿä¸€é—®é¢˜
"""

import pandas as pd
import json
import subprocess
import os
import sys
from pathlib import Path
from typing import Dict, List, Any, Optional
import logging
from datetime import datetime
import shutil

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class ReviewAnalyzerFixed:
    def __init__(self, prompts_dir: str = "Agent"):
        """
        åˆå§‹åŒ–è¯„è®ºåˆ†æå™¨
        
        Args:
            prompts_dir: å­˜æ”¾MD promptæ–‡ä»¶çš„ç›®å½•
        """
        self.prompts_dir = Path(prompts_dir)
        self.results = {}  # å­˜å‚¨æ¯ä¸ªæ­¥éª¤çš„JSONç»“æœ
        self.cleaned_data = {}  # å­˜å‚¨æ¸…ç†åçš„æ•°æ®
        
        # åˆ›å»ºå¸¦æ—¶é—´æˆ³çš„è¾“å‡ºç›®å½•
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.output_dir = Path(f"analysis_results_{timestamp}")
        self.output_dir.mkdir(exist_ok=True)
        
        logger.info(f"è¾“å‡ºç›®å½•åˆ›å»º: {self.output_dir}")
        
        # ç¡®ä¿promptsç›®å½•å­˜åœ¨
        if not self.prompts_dir.exists():
            raise FileNotFoundError(f"Agentç›®å½•ä¸å­˜åœ¨: {self.prompts_dir}")
        
        # å®šä¹‰åˆ†ææ­¥éª¤çš„ä¾èµ–å…³ç³»
        self.analysis_steps = {
            # ç¬¬ä¸€å±‚ï¼šæ— ä¾èµ–
            'product_type': {
                'prompt_file': 'product_type.md',
                'dependencies': [],
                'context_params': ['product_type']
            },
            
            # ç¬¬äºŒå±‚ï¼šä¾èµ–product_type
            'consumer_profile': {
                'prompt_file': 'consumer_profile.md', 
                'dependencies': ['product_type'],
                'context_params': ['product_type', 'customer_review_data']
            },
            'consumer_scenario': {
                'prompt_file': 'consumer_scenario.md',
                'dependencies': ['product_type'], 
                'context_params': ['product_type', 'customer_review_data']
            },
            'consumer_motivation': {
                'prompt_file': 'consumer_motivation.md',
                'dependencies': ['product_type'],
                'context_params': ['product_type', 'customer_review_data']
            },
            'consumer_love': {
                'prompt_file': 'consumer_love.md',
                'dependencies': ['product_type'],
                'context_params': ['product_type', 'customer_review_data']
            },
            'unmet_needs': {
                'prompt_file': 'unmet_needs.md',
                'dependencies': ['product_type'],
                'context_params': ['product_type', 'customer_review_data']
            },
            
            # ç¬¬ä¸‰å±‚ï¼šä¾èµ–å‰é¢çš„æ¶ˆè´¹è€…åˆ†æ
            'opportunity': {
                'prompt_file': 'opportunity.md',
                'dependencies': ['product_type', 'consumer_love', 'unmet_needs', 'consumer_scenario'],
                'context_params': ['product_type', 'consumer_love', 'unmet_needs', 'consumer_scenario', 'customer_review_data']
            },
            
            # ç¬¬å››å±‚ï¼šç‹¬ç«‹åˆ†æ
            'star_rating_root_cause': {
                'prompt_file': 'star_rating_root_cause.md',
                'dependencies': ['product_type'],
                'context_params': ['product_type', 'customer_review_data']
            },
            'competitor': {
                'prompt_file': 'competitor.md',
                'dependencies': ['product_type'],
                'context_params': ['product_type', 'customer_review_data', 'competitor_review_data']
            }
        }
        
    def load_and_clean_data(self, customer_review_path: str, competitor_review_path: str) -> Dict[str, pd.DataFrame]:
        """
        åŠ è½½å¹¶æ¸…ç†CSVæ•°æ®
        """
        logger.info("å¼€å§‹åŠ è½½å’Œæ¸…ç†æ•°æ®...")
        
        try:
            # åŠ è½½æ•°æ®
            customer_df = pd.read_csv(customer_review_path)
            competitor_df = pd.read_csv(competitor_review_path)
            
            logger.info(f"å®¢æˆ·è¯„è®ºæ•°æ®: {len(customer_df)} æ¡")
            logger.info(f"ç«äº‰å¯¹æ‰‹è¯„è®ºæ•°æ®: {len(competitor_df)} æ¡")
            
            # æ£€æŸ¥å¹¶æ ‡å‡†åŒ–åˆ—å
            if 'Review Text' in customer_df.columns:
                customer_df = customer_df.rename(columns={'Review Text': 'review_text'})
            if 'Review Text' in competitor_df.columns:
                competitor_df = competitor_df.rename(columns={'Review Text': 'review_text'})
            
            # æ•°æ®æ¸…ç†
            customer_df = customer_df.dropna(subset=['review_text'])
            competitor_df = competitor_df.dropna(subset=['review_text'])
            
            # å»é‡
            customer_df = customer_df.drop_duplicates(subset=['review_text'])
            competitor_df = competitor_df.drop_duplicates(subset=['review_text'])
            
            logger.info(f"æ¸…ç†åå®¢æˆ·è¯„è®º: {len(customer_df)} æ¡")
            logger.info(f"æ¸…ç†åç«äº‰å¯¹æ‰‹è¯„è®º: {len(competitor_df)} æ¡")
            
            # è½¬æ¢ä¸ºJSONæ ¼å¼ç”¨äºprompt
            self.cleaned_data = {
                'customer_review': customer_df.to_json(orient='records', force_ascii=False),
                'competitor_review': competitor_df.to_json(orient='records', force_ascii=False)
            }
            
            # ä¿å­˜æ¸…ç†åçš„æ•°æ®åˆ°è¾“å‡ºç›®å½•
            customer_df.to_csv(self.output_dir / 'customer_reviews_cleaned.csv', index=False)
            competitor_df.to_csv(self.output_dir / 'competitor_reviews_cleaned.csv', index=False)
            
            return {'customer': customer_df, 'competitor': competitor_df}
            
        except Exception as e:
            logger.error(f"æ•°æ®åŠ è½½å¤±è´¥: {str(e)}")
            raise

    def load_prompt(self, prompt_file: str) -> str:
        """
        åŠ è½½promptæ¨¡æ¿æ–‡ä»¶
        """
        prompt_path = self.prompts_dir / prompt_file
        if not prompt_path.exists():
            raise FileNotFoundError(f"Promptæ–‡ä»¶ä¸å­˜åœ¨: {prompt_path}")
        
        with open(prompt_path, 'r', encoding='utf-8') as f:
            return f.read()

    def prepare_context_data(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """
        å‡†å¤‡ä¸Šä¸‹æ–‡æ•°æ®ï¼Œå¤„ç†Noneå€¼å’Œé”™è¯¯å¯¹è±¡
        """
        prepared_context = {}
        
        for key, value in context.items():
            if value is None:
                prepared_context[key] = f"[{key}æ•°æ®ä¸å¯ç”¨]"
            elif isinstance(value, dict) and 'error' in value:
                # å¦‚æœæ˜¯é”™è¯¯å¯¹è±¡ï¼Œæä¾›æè¿°æ€§å ä½ç¬¦
                prepared_context[key] = f"[{key}åˆ†æå‡ºç°é”™è¯¯: {value.get('error', 'æœªçŸ¥é”™è¯¯')}]"
            elif isinstance(value, str) and len(value) > 50000:
                # æˆªæ–­è¿‡é•¿çš„å­—ç¬¦ä¸²
                prepared_context[key] = value[:50000] + "...[æ•°æ®å·²æˆªæ–­]"
            else:
                prepared_context[key] = value
                
        return prepared_context

    def extract_clean_result(self, result: Dict[str, Any]) -> Any:
        """
        ä»Q Chatç»“æœä¸­æå–å¹²å‡€çš„æ•°æ®ç”¨äºåç»­æ­¥éª¤
        """
        if isinstance(result, dict):
            if 'error' in result:
                logger.warning(f"æå–ç»“æœæ—¶å‘ç°é”™è¯¯: {result['error']}")
                return None
            elif 'json_result' in result:
                return result['json_result']
            elif 'raw_output' in result:
                # å°è¯•ä»raw_outputä¸­æå–JSON
                json_content = self.extract_json_from_output(result['raw_output'])
                if json_content:
                    try:
                        return json.loads(json_content)
                    except json.JSONDecodeError:
                        pass
                return result['raw_output']
        
        return result

    def call_q_chat(self, prompt: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """
        è°ƒç”¨Q Chatè¿›è¡Œåˆ†æ
        """
        try:
            # æ ¼å¼åŒ–prompt
            formatted_prompt = prompt.format(**context)
            
            logger.info("è°ƒç”¨Q Chat...")
            logger.info(f"ä¸Šä¸‹æ–‡å‚æ•°: {list(context.keys())}")
            
            # è°ƒç”¨q chatå‘½ä»¤
            result = subprocess.run(
                ['q', 'chat', '--trust-all-tools', formatted_prompt],
                capture_output=True,
                text=True,
                timeout=300
            )
            
            if result.returncode != 0:
                error_msg = f"Q Chatæ‰§è¡Œå¤±è´¥: {result.stderr}"
                logger.error(error_msg)
                return {"error": error_msg, "raw_output": result.stdout}
            
            output = result.stdout
            logger.info(f"Q Chatè¾“å‡ºé•¿åº¦: {len(output)} å­—ç¬¦")
            
            # å°è¯•æå–JSON
            json_content = self.extract_json_from_output(output)
            if json_content:
                try:
                    parsed_json = json.loads(json_content)
                    logger.info("æˆåŠŸæå–å¹¶è§£æJSON")
                    return {"json_result": parsed_json, "raw_output": output}
                except json.JSONDecodeError as e:
                    logger.warning(f"JSONè§£æå¤±è´¥: {str(e)}")
            
            logger.info("æœªæ‰¾åˆ°æœ‰æ•ˆJSONï¼Œè¿”å›åŸå§‹è¾“å‡º")
            return {"error": "æœªæ‰¾åˆ°æœ‰æ•ˆçš„JSONè¾“å‡º", "raw_output": output}
            
        except subprocess.TimeoutExpired:
            logger.error("Q Chatè°ƒç”¨è¶…æ—¶")
            return {"error": "Q Chatè°ƒç”¨è¶…æ—¶", "raw_output": ""}
        except Exception as e:
            logger.error(f"Q Chatè°ƒç”¨å¼‚å¸¸: {str(e)}")
            return {"error": f"Q Chatè°ƒç”¨å¼‚å¸¸: {str(e)}", "raw_output": ""}

    def extract_json_from_output(self, output: str) -> Optional[str]:
        """
        ä»è¾“å‡ºä¸­æå–JSONå†…å®¹ï¼Œæ”¯æŒå¤šç§æ ¼å¼
        """
        import re
        
        # æ–¹æ³•1: å¯»æ‰¾markdownä»£ç å—ä¸­çš„JSON
        json_block_pattern = r'```(?:json)?\s*(\{.*?\})\s*```'
        json_blocks = re.findall(json_block_pattern, output, re.DOTALL | re.IGNORECASE)
        
        if json_blocks:
            for block in reversed(json_blocks):
                try:
                    json.loads(block)
                    return block
                except json.JSONDecodeError:
                    continue
        
        # æ–¹æ³•2: å¯»æ‰¾æœ€å¤§çš„å®Œæ•´JSONå¯¹è±¡
        json_start = -1
        for i, char in enumerate(output):
            if char == '{':
                json_start = i
                break
        
        if json_start == -1:
            return None
            
        brace_count = 0
        in_string = False
        escape_next = False
        json_end = json_start
        
        for i in range(json_start, len(output)):
            char = output[i]
            
            if escape_next:
                escape_next = False
                continue
                
            if char == '\\':
                escape_next = True
                continue
                
            if char == '"' and not escape_next:
                in_string = not in_string
                continue
                
            if not in_string:
                if char == '{':
                    brace_count += 1
                elif char == '}':
                    brace_count -= 1
                    if brace_count == 0:
                        json_end = i + 1
                        break
        
        if brace_count == 0:
            candidate = output[json_start:json_end]
            try:
                json.loads(candidate)
                return candidate
            except json.JSONDecodeError:
                pass
        
        return None

    def check_dependencies(self, step_name: str) -> bool:
        """
        æ£€æŸ¥æ­¥éª¤çš„ä¾èµ–æ˜¯å¦å·²å®Œæˆ
        """
        step_config = self.analysis_steps[step_name]
        dependencies = step_config['dependencies']
        
        for dep in dependencies:
            if dep not in self.results:
                logger.warning(f"æ­¥éª¤ {step_name} çš„ä¾èµ– {dep} å°šæœªå®Œæˆ")
                return False
                
            # æ£€æŸ¥ä¾èµ–ç»“æœæ˜¯å¦æœ‰æ•ˆ
            dep_result = self.results[dep]
            if isinstance(dep_result, dict) and 'error' in dep_result:
                logger.warning(f"æ­¥éª¤ {step_name} çš„ä¾èµ– {dep} æ‰§è¡Œå¤±è´¥")
                # ç»§ç»­æ‰§è¡Œï¼Œä½†ä¼šä¼ é€’é”™è¯¯ä¿¡æ¯
        
        return True

    def build_context_for_step(self, step_name: str, base_context: Dict[str, Any]) -> Dict[str, Any]:
        """
        ä¸ºç‰¹å®šæ­¥éª¤æ„å»ºä¸Šä¸‹æ–‡
        """
        step_config = self.analysis_steps[step_name]
        context_params = step_config['context_params']
        
        context = {}
        
        for param in context_params:
            if param in base_context:
                context[param] = base_context[param]
            elif param in self.results:
                # ä»ä¹‹å‰çš„ç»“æœä¸­è·å–
                clean_result = self.extract_clean_result(self.results[param])
                context[param] = clean_result
            else:
                logger.warning(f"æ­¥éª¤ {step_name} éœ€è¦çš„å‚æ•° {param} ä¸å¯ç”¨")
                context[param] = None
        
        return context

    def save_step_result(self, step_name: str, result: Dict[str, Any]):
        """
        ä¿å­˜å•ä¸ªæ­¥éª¤çš„ç»“æœåˆ°æ–‡ä»¶
        """
        # ä¿å­˜JSONç»“æœ
        result_file = self.output_dir / f"{step_name}.json"
        with open(result_file, 'w', encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
        
        logger.info(f"æ­¥éª¤ {step_name} ç»“æœå·²ä¿å­˜åˆ°: {result_file}")

    def run_analysis_pipeline(self, customer_review_path: str, competitor_review_path: str, product_type: str) -> Dict[str, Any]:
        """
        è¿è¡Œå®Œæ•´çš„åˆ†æç®¡é“ï¼ŒæŒ‰ä¾èµ–é¡ºåºæ‰§è¡Œ
        """
        logger.info("å¼€å§‹è¿è¡Œä¿®å¤ç‰ˆåˆ†æç®¡é“...")
        
        # 1. æ•°æ®æ¸…ç†
        self.load_and_clean_data(customer_review_path, competitor_review_path)
        
        # åŸºç¡€ä¸Šä¸‹æ–‡
        base_context = {
            'product_type': product_type,
            'customer_review_data': self.cleaned_data['customer_review'],
            'competitor_review_data': self.cleaned_data['competitor_review']
        }
        
        # æŒ‰ä¾èµ–é¡ºåºæ‰§è¡Œåˆ†ææ­¥éª¤
        execution_order = [
            'product_type',
            'consumer_profile', 'consumer_scenario', 'consumer_motivation', 'consumer_love', 'unmet_needs',
            'opportunity',
            'star_rating_root_cause', 'competitor'
        ]
        
        for step_name in execution_order:
            logger.info(f"æ‰§è¡Œæ­¥éª¤: {step_name}")
            
            # æ£€æŸ¥ä¾èµ–
            if not self.check_dependencies(step_name):
                logger.error(f"æ­¥éª¤ {step_name} çš„ä¾èµ–æ£€æŸ¥å¤±è´¥ï¼Œè·³è¿‡æ‰§è¡Œ")
                continue
            
            # æ„å»ºä¸Šä¸‹æ–‡
            step_context = self.build_context_for_step(step_name, base_context)
            optimized_context = self.prepare_context_data(step_context)
            
            # åŠ è½½promptå¹¶æ‰§è¡Œ
            step_config = self.analysis_steps[step_name]
            prompt = self.load_prompt(step_config['prompt_file'])
            
            # æ‰§è¡Œåˆ†æ
            result = self.call_q_chat(prompt, optimized_context)
            self.results[step_name] = result
            
            # ä¿å­˜ç»“æœ
            self.save_step_result(step_name, result)
            
            logger.info(f"æ­¥éª¤ {step_name} å®Œæˆ")
        
        # ä¿å­˜å®Œæ•´ç»“æœ
        self.save_complete_results()
        
        return self.results

    def save_complete_results(self):
        """
        ä¿å­˜å®Œæ•´çš„åˆ†æç»“æœ
        """
        # ä¿å­˜å®Œæ•´ç»“æœ
        complete_results_file = self.output_dir / "analysis_results_complete.json"
        with open(complete_results_file, 'w', encoding='utf-8') as f:
            json.dump(self.results, f, ensure_ascii=False, indent=2)
        
        # åˆ›å»ºåˆ†ææŠ¥å‘Š
        self.create_analysis_report()
        
        logger.info(f"å®Œæ•´åˆ†æç»“æœå·²ä¿å­˜åˆ°: {self.output_dir}")

    def create_analysis_report(self):
        """
        åˆ›å»ºåˆ†ææŠ¥å‘Šæ‘˜è¦
        """
        report_file = self.output_dir / "analysis_report.md"
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(f"# åˆ†ææŠ¥å‘Š\n\n")
            f.write(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            f.write(f"**è¾“å‡ºç›®å½•**: {self.output_dir}\n\n")
            
            f.write("## åˆ†ææ­¥éª¤æ‰§è¡ŒçŠ¶æ€\n\n")
            
            for step_name in self.analysis_steps.keys():
                if step_name in self.results:
                    result = self.results[step_name]
                    if isinstance(result, dict) and 'error' in result:
                        status = "âŒ å¤±è´¥"
                        detail = result['error']
                    else:
                        status = "âœ… æˆåŠŸ"
                        detail = "åˆ†æå®Œæˆ"
                else:
                    status = "â¸ï¸ æœªæ‰§è¡Œ"
                    detail = "æ­¥éª¤æœªæ‰§è¡Œ"
                
                f.write(f"- **{step_name}**: {status} - {detail}\n")
            
            f.write(f"\n## è¾“å‡ºæ–‡ä»¶\n\n")
            for file in sorted(self.output_dir.glob("*.json")):
                f.write(f"- `{file.name}`\n")
            
            f.write(f"\n## æ•°æ®ç»Ÿè®¡\n\n")
            f.write(f"- å®¢æˆ·è¯„è®ºæ•°æ®: {self.cleaned_data.get('customer_review', 'N/A')}\n")
            f.write(f"- ç«äº‰å¯¹æ‰‹è¯„è®ºæ•°æ®: {self.cleaned_data.get('competitor_review', 'N/A')}\n")

def main():
    """
    ä¸»å‡½æ•°
    """
    if len(sys.argv) != 4:
        print("ä½¿ç”¨æ–¹æ³•: python review_analyzer_fixed.py <customer_reviews.csv> <competitor_reviews.csv> <product_type>")
        sys.exit(1)
    
    customer_review_path = sys.argv[1]
    competitor_review_path = sys.argv[2] 
    product_type = sys.argv[3]
    
    try:
        analyzer = ReviewAnalyzerFixed()
        results = analyzer.run_analysis_pipeline(customer_review_path, competitor_review_path, product_type)
        
        print(f"\nâœ… åˆ†æå®Œæˆï¼")
        print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {analyzer.output_dir}")
        print(f"ğŸ“Š å…±å®Œæˆ {len(results)} ä¸ªåˆ†ææ­¥éª¤")
        
        # æ˜¾ç¤ºæ‰§è¡Œæ‘˜è¦
        success_count = sum(1 for r in results.values() if not (isinstance(r, dict) and 'error' in r))
        print(f"âœ… æˆåŠŸ: {success_count}/{len(results)} ä¸ªæ­¥éª¤")
        
    except Exception as e:
        logger.error(f"åˆ†æç®¡é“æ‰§è¡Œå¤±è´¥: {str(e)}")
        sys.exit(1)

if __name__ == "__main__":
    main()
