#!/usr/bin/env python3
"""
Novochoice AI - Local API Server
ç®€å•çš„FlaskæœåŠ¡å™¨ï¼Œè¿æ¥å‰ç«¯å’ŒPythonåˆ†æå¼•æ“
"""

import os
import json
import uuid
import subprocess
import threading
import time
from datetime import datetime
from flask import Flask, request, jsonify, send_file, make_response
from flask_cors import CORS
import tempfile
import shutil

app = Flask(__name__)
CORS(app)  # å…è®¸å‰ç«¯è·¨åŸŸè®¿é—®

# é…ç½®
UPLOAD_FOLDER = 'uploads'
RESULTS_FOLDER = 'results'
os.makedirs(UPLOAD_FOLDER, exist_ok=True)
os.makedirs(RESULTS_FOLDER, exist_ok=True)

# å…¨å±€å˜é‡å­˜å‚¨åˆ†æçŠ¶æ€
analysis_status = {}

# åˆ†ææ­¥éª¤å®šä¹‰ï¼ˆä¸Pythonè„šæœ¬ä¸­çš„9ä¸ªæ­¥éª¤å¯¹åº”ï¼‰
ANALYSIS_STEPS = [
    {"id": "product_type", "name": "Product Classification", "name_zh": "äº§å“åˆ†ç±»åˆ†æ"},
    {"id": "consumer_profile", "name": "Consumer Profile Analysis", "name_zh": "æ¶ˆè´¹è€…ç”»åƒåˆ†æ"},
    {"id": "consumer_scenario", "name": "Usage Scenario Analysis", "name_zh": "ä½¿ç”¨åœºæ™¯åˆ†æ"},
    {"id": "consumer_motivation", "name": "Purchase Motivation Analysis", "name_zh": "è´­ä¹°åŠ¨æœºåˆ†æ"},
    {"id": "consumer_love", "name": "Customer Satisfaction Analysis", "name_zh": "å®¢æˆ·æ»¡æ„åº¦åˆ†æ"},
    {"id": "unmet_needs", "name": "Unmet Needs Analysis", "name_zh": "æœªæ»¡è¶³éœ€æ±‚åˆ†æ"},
    {"id": "opportunity", "name": "Business Opportunity Analysis", "name_zh": "å•†ä¸šæœºä¼šåˆ†æ"},
    {"id": "star_rating_root_cause", "name": "Rating Root Cause Analysis", "name_zh": "è¯„åˆ†æ ¹å› åˆ†æ"},
    {"id": "competitor", "name": "Competitive Analysis", "name_zh": "ç«äº‰åˆ†æ"}
]

@app.route('/health', methods=['GET'])
def health_check():
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
    return jsonify({
        'status': 'healthy',
        'message': 'Novochoice AI API Server is running',
        'timestamp': datetime.now().isoformat()
    })

@app.route('/upload', methods=['POST'])
def upload_file():
    """æ–‡ä»¶ä¸Šä¼ ç«¯ç‚¹"""
    try:
        if 'file' not in request.files:
            return jsonify({'error': 'No file provided'}), 400
        
        file = request.files['file']
        file_type = request.form.get('type', 'own')  # 'own' or 'competitor'
        
        if file.filename == '':
            return jsonify({'error': 'No file selected'}), 400
        
        # ç”Ÿæˆå”¯ä¸€æ–‡ä»¶å
        file_id = str(uuid.uuid4())
        filename = f"{file_type}_{file_id}_{file.filename}"
        filepath = os.path.join(UPLOAD_FOLDER, filename)
        
        # ä¿å­˜æ–‡ä»¶
        file.save(filepath)
        
        return jsonify({
            'success': True,
            'fileName': filename,
            'originalName': file.filename,
            'size': os.path.getsize(filepath),
            'type': file_type
        })
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/analyze', methods=['POST'])
def start_analysis():
    """å¯åŠ¨åˆ†æç«¯ç‚¹"""
    try:
        data = request.get_json()
        own_brand_file = data.get('ownBrandFile')
        competitor_file = data.get('competitorFile')
        target_category = data.get('targetCategory', '')
        language = data.get('language', 'en')
        output_language = data.get('outputLanguage', 'en')
        
        if not own_brand_file:
            return jsonify({'error': 'Own brand file is required'}), 400
        
        # ç”Ÿæˆåˆ†æID
        analysis_id = str(uuid.uuid4())
        
        # åˆå§‹åŒ–åˆ†æçŠ¶æ€
        analysis_status[analysis_id] = {
            'status': 'starting',
            'progress': 0,
            'current_step': 0,
            'total_steps': len(ANALYSIS_STEPS),
            'steps': [{'id': step['id'], 'name': step['name'], 'name_zh': step['name_zh'], 'status': 'pending'} for step in ANALYSIS_STEPS],
            'start_time': datetime.now().isoformat(),
            'target_category': target_category,
            'has_competitor_data': bool(competitor_file)
        }
        
        # å‡†å¤‡æ–‡ä»¶è·¯å¾„
        own_brand_path = os.path.join(UPLOAD_FOLDER, own_brand_file)
        competitor_path = os.path.join(UPLOAD_FOLDER, competitor_file) if competitor_file else None
        
        if not os.path.exists(own_brand_path):
            return jsonify({'error': 'Own brand file not found'}), 404
        
        if competitor_file and not os.path.exists(competitor_path):
            return jsonify({'error': 'Competitor file not found'}), 404
        
        # åœ¨åå°çº¿ç¨‹ä¸­è¿è¡Œåˆ†æ
        thread = threading.Thread(target=run_analysis_background, 
                                args=(analysis_id, own_brand_path, competitor_path, target_category, output_language))
        thread.daemon = True
        thread.start()
        
        return jsonify({
            'analysis_id': analysis_id,
            'status': 'started',
            'message': 'Analysis started successfully'
        })
        
    except Exception as e:
        print(f"Analysis error: {str(e)}")
        return jsonify({'error': str(e)}), 500

def run_analysis_background(analysis_id, own_brand_path, competitor_path, target_category, output_language):
    """åœ¨åå°è¿è¡Œåˆ†æçš„å‡½æ•°"""
    try:
        # æ›´æ–°çŠ¶æ€ä¸ºè¿è¡Œä¸­
        analysis_status[analysis_id]['status'] = 'running'
        analysis_status[analysis_id]['progress'] = 5
        
        # å¤åˆ¶æ–‡ä»¶åˆ°dataç›®å½•ï¼ˆPythonè„šæœ¬æœŸæœ›çš„ä½ç½®ï¼‰
        shutil.copy2(own_brand_path, 'data/Customer ASIN Reviews.csv')
        if competitor_path:
            shutil.copy2(competitor_path, 'data/Competitor ASIN Reviews.csv')
        
        print(f"Starting real-time analysis for category: {target_category}")
        
        # è¿è¡Œå¸¦æœ‰è¿›åº¦è·Ÿè¸ªçš„Pythonåˆ†æè„šæœ¬
        process = subprocess.Popen(
            ['python3', 'run_analysis_with_progress.py', target_category, output_language], 
            stdout=subprocess.PIPE, 
            stderr=subprocess.PIPE, 
            text=True, 
            cwd='.',
            bufsize=1,
            universal_newlines=True
        )
        
        # å®æ—¶è¯»å–Pythonè„šæœ¬çš„è¾“å‡º
        while True:
            output = process.stdout.readline()
            if output == '' and process.poll() is not None:
                break
            
            if output:
                line = output.strip()
                print(f"Python output: {line}")
                
                # è§£æè¿›åº¦ä¿¡æ¯
                if line.startswith('PROGRESS:'):
                    try:
                        progress_json = line[9:]  # ç§»é™¤ 'PROGRESS:' å‰ç¼€
                        progress_data = json.loads(progress_json)
                        
                        # æ›´æ–°åˆ†æçŠ¶æ€
                        analysis_status[analysis_id]['progress'] = progress_data['progress']
                        analysis_status[analysis_id]['current_step'] = progress_data['step_index']
                        
                        # æ›´æ–°æ­¥éª¤çŠ¶æ€
                        step_index = progress_data['step_index']
                        if step_index < len(analysis_status[analysis_id]['steps']):
                            # æ ‡è®°å½“å‰æ­¥éª¤ä¸ºè¿è¡Œä¸­
                            analysis_status[analysis_id]['steps'][step_index]['status'] = 'running'
                            
                            # æ ‡è®°ä¹‹å‰çš„æ­¥éª¤ä¸ºå®Œæˆ
                            for i in range(step_index):
                                analysis_status[analysis_id]['steps'][i]['status'] = 'completed'
                        
                        # å¦‚æœæ­¥éª¤å®Œæˆï¼Œæ ‡è®°ä¸ºå®ŒæˆçŠ¶æ€
                        if progress_data['status'] == 'completed' and step_index > 0:
                            if step_index - 1 < len(analysis_status[analysis_id]['steps']):
                                analysis_status[analysis_id]['steps'][step_index - 1]['status'] = 'completed'
                        
                        print(f"Progress updated: {progress_data['progress']}% - Step {step_index}")
                        
                    except json.JSONDecodeError as e:
                        print(f"Failed to parse progress JSON: {e}")
        
        # ç­‰å¾…è¿›ç¨‹å®Œæˆ
        stdout, stderr = process.communicate()
        
        if process.returncode != 0:
            print(f"Analysis failed: {stderr}")
            analysis_status[analysis_id]['status'] = 'failed'
            analysis_status[analysis_id]['error'] = stderr
            return
        
        # åˆ†æå®Œæˆï¼Œæ ‡è®°æ‰€æœ‰æ­¥éª¤ä¸ºå®Œæˆ
        analysis_status[analysis_id]['status'] = 'completed'
        analysis_status[analysis_id]['progress'] = 100
        analysis_status[analysis_id]['end_time'] = datetime.now().isoformat()
        
        for step in analysis_status[analysis_id]['steps']:
            step['status'] = 'completed'
        
        print(f"Analysis {analysis_id} completed successfully")
        
    except Exception as e:
        print(f"Background analysis error: {str(e)}")
        analysis_status[analysis_id]['status'] = 'failed'
        analysis_status[analysis_id]['error'] = str(e)

@app.route('/analysis/<analysis_id>/stream', methods=['GET'])
def stream_analysis_output(analysis_id):
    """å®æ—¶æµå¼è¾“å‡ºåˆ†æå†…å®¹"""
    def generate():
        if analysis_id not in analysis_status:
            yield f"data: {json.dumps({'error': 'Analysis not found'})}\n\n"
            return
        
        # æ¨¡æ‹Ÿå®æ—¶è¾“å‡ºæ­£åœ¨ç”Ÿæˆçš„å†…å®¹
        status = analysis_status[analysis_id]
        if status['status'] == 'running':
            # æ ¹æ®å½“å‰æ­¥éª¤è¿”å›ç›¸åº”çš„å®æ—¶å†…å®¹
            current_step = status.get('current_step', 0)
            steps = status.get('steps', [])
            
            if current_step < len(steps):
                step_name = steps[current_step]['name']
                # è¿™é‡Œåº”è¯¥è¿”å›çœŸå®çš„AIç”Ÿæˆå†…å®¹
                # æš‚æ—¶è¿”å›æ¨¡æ‹Ÿçš„å®æ—¶å†…å®¹
                content = {
                    "current_analysis": step_name,
                    "progress": status['progress'],
                    "partial_result": f"æ­£åœ¨åˆ†æ{step_name}...",
                    "timestamp": datetime.now().isoformat()
                }
                yield f"data: {json.dumps(content)}\n\n"
        
        yield f"data: {json.dumps({'status': 'complete'})}\n\n"
    
    return Response(generate(), mimetype='text/plain')

@app.route('/analysis/<analysis_id>/latest-output', methods=['GET'])
def get_latest_output(analysis_id):
    """è·å–æœ€æ–°çš„åˆ†æè¾“å‡ºå†…å®¹"""
    if analysis_id not in analysis_status:
        return jsonify({'error': 'Analysis not found'}), 404
    
    status = analysis_status[analysis_id]
    
    # å¦‚æœåˆ†æå®Œæˆï¼Œè¿”å›å®Œæ•´ç»“æœ
    if status['status'] == 'completed':
        try:
            result = load_analysis_results(analysis_id, '', False)
            return jsonify({'content': json.dumps(result, ensure_ascii=False, indent=2)})
        except:
            pass
    
    # å¦‚æœåˆ†æè¿›è¡Œä¸­ï¼Œè¿”å›å½“å‰æ­¥éª¤çš„å®æ—¶å†…å®¹
    if status['status'] == 'running':
        current_step = status.get('current_step', 0)
        steps = status.get('steps', [])
        
        if current_step < len(steps):
            step_name = steps[current_step]['name']
            # è¿™é‡Œåº”è¯¥è¿”å›çœŸå®çš„AIæ­£åœ¨ç”Ÿæˆçš„å†…å®¹
            # æš‚æ—¶è¿”å›æ¨¡æ‹Ÿå†…å®¹
            content = {
                "ğŸ”„ å®æ—¶åˆ†æçŠ¶æ€": "æ­£åœ¨è¿›è¡Œä¸­",
                "ğŸ“Š å½“å‰æ­¥éª¤": f"{current_step + 1}/9 - {step_name}",
                "ğŸ“ˆ å®Œæˆè¿›åº¦": f"{status['progress']}%",
                "ğŸ¤– AIå¼•æ“": "Amazon Q Developer",
                "â° åˆ†ææ—¶é—´": status.get('start_time', ''),
                "ğŸ” å®æ—¶æ´å¯Ÿ": f"æ­£åœ¨æ·±åº¦åˆ†æ{step_name}ï¼ŒAIæ­£åœ¨å¤„ç†æ•°æ®å¹¶ç”Ÿæˆæ´å¯Ÿ..."
            }
            return jsonify({'content': json.dumps(content, ensure_ascii=False, indent=2)})
    
    return jsonify({'content': '{"status": "ç­‰å¾…åˆ†æå¼€å§‹..."}'})

@app.route('/analysis/<analysis_id>/status', methods=['GET'])
def get_analysis_status(analysis_id):
    """è·å–åˆ†æçŠ¶æ€"""
    if analysis_id not in analysis_status:
        return jsonify({'error': 'Analysis not found'}), 404
    
    return jsonify(analysis_status[analysis_id])

@app.route('/analysis/<analysis_id>/result', methods=['GET'])
def get_analysis_result(analysis_id):
    """è·å–åˆ†æç»“æœ"""
    if analysis_id == 'latest':
        # ç‰¹æ®Šå¤„ç†ï¼šåŠ è½½æœ€æ–°çš„åˆ†æç»“æœæˆ–demoæ•°æ®
        try:
            result = load_analysis_results('latest', '', False)
            if 'error' in result:
                return jsonify({'error': 'No analysis results found'}), 404
            return jsonify(result)
        except Exception as e:
            return jsonify({'error': str(e)}), 500
    
    if analysis_id not in analysis_status:
        return jsonify({'error': 'Analysis not found'}), 404
    
    if analysis_status[analysis_id]['status'] != 'completed':
        return jsonify({'error': 'Analysis not completed yet'}), 400
    
    # åŠ è½½å¹¶è¿”å›åˆ†æç»“æœ
    result = load_analysis_results(
        analysis_id, 
        analysis_status[analysis_id]['target_category'],
        analysis_status[analysis_id]['has_competitor_data']
    )
    
    return jsonify(result)

def load_analysis_results(analysis_id, target_category, has_competitor_data):
    """åŠ è½½åˆ†æç»“æœå¹¶æ ¼å¼åŒ–ä¸ºå‰ç«¯æœŸæœ›çš„ç»“æ„"""
    
    def format_competitor_analysis(competitor_data):
        """æ ¼å¼åŒ–æ–°çš„competitoræ•°æ®ç»“æ„ä¸ºå‰ç«¯æœŸæœ›çš„æ ¼å¼"""
        if not competitor_data or 'error' in competitor_data:
            return {}
        
        # æ–°çš„æ•°æ®ç»“æ„åŒ…å«ä¸‰ä¸ªéƒ¨åˆ†
        base_analysis = competitor_data.get('ç«å“åŸºç¡€åˆ†æ', {})
        comparison_analysis = competitor_data.get('ç«å“å¯¹æ¯”åˆ†æ', {})
        unique_insights = competitor_data.get('ç«å“ç‹¬æœ‰æ´å¯Ÿ', {})
        
        # è½¬æ¢ä¸ºå‰ç«¯æœŸæœ›çš„æ ¼å¼
        formatted_result = {}
        
        # å¤„ç†ç»¼åˆç«äº‰åŠ›è¯„ä¼°
        if comparison_analysis and 'ç»¼åˆç«äº‰åŠ›è¯„ä¼°' in comparison_analysis:
            formatted_result['ç»¼åˆç«äº‰åŠ›è¯„ä¼°'] = comparison_analysis['ç»¼åˆç«äº‰åŠ›è¯„ä¼°']
        
        # å¤„ç†å››è±¡é™åˆ†æ - è½¬æ¢ä¸ºå‰ç«¯æœŸæœ›çš„æ ¼å¼
        if comparison_analysis and 'å››è±¡é™å¯¹æ¯”åˆ†æ' in comparison_analysis:
            quadrant_data = comparison_analysis['å››è±¡é™å¯¹æ¯”åˆ†æ']
            
            # åˆ›å»ºå‰ç«¯æœŸæœ›çš„å¯¹æ¯”æ•°æ®ç»“æ„
            # ä»å››è±¡é™æ•°æ®é‡æ„ä¸ºä¸‰ä¸ªå¯¹æ¯”ç±»åˆ«
            love_comparison = []
            unmet_comparison = []
            motivation_comparison = []
            
            # å¤„ç†æ¯ä¸ªè±¡é™çš„æ•°æ®
            for quadrant_name, items in quadrant_data.items():
                if quadrant_name == 'è¯´æ˜':
                    continue
                    
                for item in items:
                    if isinstance(item, dict) and 'å¯¹æ¯”ä¸»é¢˜' in item:
                        comparison_item = {
                            'å¯¹æ¯”ä¸»é¢˜': item['å¯¹æ¯”ä¸»é¢˜'],
                            'æˆ‘æ–¹é¢‘ç‡': 'é«˜' if float(item.get('æˆ‘æ–¹é¢‘ç‡', '0%').replace('%', '')) >= 15 else 'ä½',
                            'ç«å“é¢‘ç‡': 'é«˜' if float(item.get('ç«å“é¢‘ç‡', '0%').replace('%', '')) >= 15 else 'ä½',
                            'å¯¹æ¯”æ´å¯Ÿ': item.get('å¯¹æ¯”æ´å¯Ÿ', ''),
                            'è±¡é™ç‰¹å¾': item.get('è±¡é™ç‰¹å¾', '')
                        }
                        
                        # æ ¹æ®ä¸»é¢˜åˆ†ç±»åˆ°ä¸åŒçš„å¯¹æ¯”ç±»åˆ«ï¼ˆè¿™é‡Œéœ€è¦æ ¹æ®å®é™…æ•°æ®ç»“æ„è°ƒæ•´ï¼‰
                        # æš‚æ—¶éƒ½æ”¾åˆ°å®¢æˆ·å–œçˆ±ç‚¹å¯¹æ¯”ä¸­ï¼Œå®é™…åº”è¯¥æ ¹æ®æ•°æ®æ¥æºåˆ†ç±»
                        love_comparison.append(comparison_item)
            
            formatted_result['å®¢æˆ·å–œçˆ±ç‚¹å¯¹æ¯”'] = love_comparison
            formatted_result['æœªæ»¡è¶³éœ€æ±‚å¯¹æ¯”'] = unmet_comparison  # éœ€è¦ç±»ä¼¼çš„å¤„ç†
            formatted_result['è´­ä¹°åŠ¨æœºå¯¹æ¯”'] = motivation_comparison  # éœ€è¦ç±»ä¼¼çš„å¤„ç†
        
        # æ·»åŠ åŸºç¡€åˆ†ææ•°æ®
        if base_analysis:
            formatted_result['ç«å“åŸºç¡€æ•°æ®'] = base_analysis
        
        # æ·»åŠ ç‹¬æœ‰æ´å¯Ÿ
        if unique_insights:
            formatted_result['ç«å“ç‹¬æœ‰æ´å¯Ÿ'] = unique_insights
        
        return formatted_result
    
    try:
        # æŸ¥æ‰¾åŒ…å«å®Œæ•´ç»“æœçš„result/analysis_results_TIMESTAMPç›®å½•
        import glob
        result_dirs = glob.glob('result/analysis_results_*')
        if not result_dirs:
            print("No analysis results found, loading demo data from result/demoresult folder...")
            return load_demo_results()
        
        # æŒ‰æ—¶é—´æ’åºï¼Œä»æœ€æ–°å¼€å§‹æŸ¥æ‰¾
        result_dirs.sort(reverse=True)
        
        # å¿…éœ€çš„ç»“æœæ–‡ä»¶
        required_files = [
            'consumer_profile.json',
            'consumer_motivation.json', 
            'consumer_scenario.json',
            'consumer_love.json',
            'star_rating_root_cause.json',
            'unmet_needs.json',
            'opportunity.json',
            'competitor.json'
        ]
        
        results_dir = None
        actual_category = target_category
        for dir_path in result_dirs:
            # æ£€æŸ¥è¿™ä¸ªç›®å½•æ˜¯å¦åŒ…å«æ‰€æœ‰å¿…éœ€æ–‡ä»¶
            has_all_files = True
            for filename in required_files:
                filepath = os.path.join(dir_path, filename)
                if not os.path.exists(filepath):
                    has_all_files = False
                    break
            
            if has_all_files:
                results_dir = dir_path
                # è¯»å–metadataè·å–å®é™…çš„category
                metadata_file = os.path.join(dir_path, 'metadata.json')
                if os.path.exists(metadata_file):
                    try:
                        with open(metadata_file, 'r', encoding='utf-8') as f:
                            metadata = json.load(f)
                            actual_category = metadata.get('target_category', target_category)
                    except:
                        pass
                break
        
        if not results_dir:
            print("No complete analysis results found, loading demo data from result/demoresult folder...")
            return load_demo_results()
        
        print(f"Loading results from: {results_dir}")
        
        # è¯»å–å„ä¸ªåˆ†æç»“æœæ–‡ä»¶
        results = {}
        
        for filename in required_files:
            filepath = os.path.join(results_dir, filename)
            try:
                with open(filepath, 'r', encoding='utf-8') as f:
                    key = filename.replace('.json', '')
                    results[key] = json.load(f)
                    print(f"âœ… Loaded {filename}: {len(str(results[key]))} characters")
            except Exception as e:
                print(f"âŒ Error loading {filename}: {e}")
                results[key] = {}
        
        # ä»ç›®å½•åæå–å®é™…çš„åˆ†ææ—¶é—´
        actual_timestamp = datetime.now().isoformat()
        if results_dir:
            try:
                # ä»ç›®å½•åæå–æ—¶é—´æˆ³ (æ ¼å¼: result/analysis_results_YYYYMMDD_HHMMSS)
                timestamp_str = results_dir.replace('result/analysis_results_', '')
                dt = datetime.strptime(timestamp_str, '%Y%m%d_%H%M%S')
                actual_timestamp = dt.isoformat()
                print(f"ğŸ“… ä½¿ç”¨å®é™…åˆ†ææ—¶é—´: {actual_timestamp} (ä»ç›®å½• {results_dir})")
            except Exception as e:
                print(f"âš ï¸ æ— æ³•è§£ææ—¶é—´æˆ³ï¼Œä½¿ç”¨å½“å‰æ—¶é—´: {e}")
        
        # æ ¼å¼åŒ–ä¸ºå‰ç«¯æœŸæœ›çš„ç»“æ„
        formatted_result = {
            'id': analysis_id,
            'timestamp': actual_timestamp,
            'hasCompetitorData': bool(results.get('competitor', {})),  # æ ¹æ®å®é™…æ•°æ®è®¾ç½®
            'targetCategory': actual_category,
            'ownBrandAnalysis': {
                'userInsights': results.get('consumer_profile', {}),
                'userMotivation': results.get('consumer_motivation', {}),
                'userScenario': results.get('consumer_scenario', {}),
                'userFeedback': {
                    'consumerLove': results.get('consumer_love', {}),
                    'starRating': results.get('star_rating_root_cause', {})
                },
                'unmetNeeds': results.get('unmet_needs', {}),
                'opportunities': results.get('opportunity', {})
            },
            'competitorAnalysis': format_competitor_analysis(results.get('competitor', {})),
            'competitor': results.get('competitor', {})  # ç›´æ¥æ·»åŠ æ–°çš„ç«å“æ•°æ®ç»“æ„
        }
        
        # ä¿å­˜metadataåˆ°åˆ†æç»“æœç›®å½•
        if results_dir:
            metadata = {
                'id': analysis_id,
                'timestamp': datetime.now().isoformat(),
                'targetCategory': target_category if target_category and target_category.strip() else 'Webcams',
                'hasCompetitorData': bool(results.get('competitor', {}))
            }
            metadata_path = os.path.join(results_dir, 'metadata.json')
            try:
                with open(metadata_path, 'w', encoding='utf-8') as f:
                    json.dump(metadata, f, ensure_ascii=False, indent=2)
                print(f"âœ… Saved metadata to {metadata_path}")
            except Exception as e:
                print(f"âŒ Error saving metadata: {e}")
        
        print(f"âœ… Formatted result with {len([k for k, v in results.items() if v])} non-empty analysis modules")
        return formatted_result
        
    except Exception as e:
        print(f"âŒ Error loading results: {str(e)}")
        print("Loading demo data as fallback...")
        return load_demo_results()

@app.route('/reports/<report_id>', methods=['DELETE'])
def delete_report(report_id):
    """åˆ é™¤æŒ‡å®šçš„å†å²æŠ¥å‘Š"""
    try:
        import shutil
        
        # éªŒè¯æŠ¥å‘ŠIDæ ¼å¼
        if not report_id.startswith('analysis_results_'):
            return jsonify({'error': 'Invalid report ID format'}), 400
        
        # æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨
        if not os.path.exists(report_id):
            return jsonify({'error': 'Report not found'}), 404
        
        # åˆ é™¤æ•´ä¸ªæŠ¥å‘Šç›®å½•
        shutil.rmtree(report_id)
        print(f"âœ… Deleted report directory: {report_id}")
        
        return jsonify({'message': 'Report deleted successfully'})
        
    except Exception as e:
        print(f"âŒ Error deleting report {report_id}: {e}")
        return jsonify({'error': f'Failed to delete report: {str(e)}'}), 500

@app.route('/reports/<report_id>/export-html', methods=['GET'])
def export_report_html(report_id):
    """å¯¼å‡ºæŒ‡å®šæŠ¥å‘Šä¸ºHTMLæ ¼å¼"""
    try:
        # æŸ¥æ‰¾æŠ¥å‘Šæ–‡ä»¶
        report_data = None
        json_file_path = None
        
        for root, dirs, files in os.walk('.'):
            if report_id in root:
                for file in files:
                    if file.endswith('.json') and 'analysis_results' in file:
                        json_file_path = os.path.join(root, file)
                        try:
                            with open(json_file_path, 'r', encoding='utf-8') as f:
                                report_data = json.load(f)
                            break
                        except:
                            continue
                if report_data:
                    break
        
        if not report_data or not json_file_path:
            return jsonify({'error': 'Report not found'}), 404
        
        # åˆ›å»ºä¸´æ—¶HTMLæ–‡ä»¶
        temp_html = tempfile.NamedTemporaryFile(mode='w', suffix='.html', delete=False)
        temp_html.close()
        
        # è°ƒç”¨Pythonå¯¼å‡ºè„šæœ¬
        script_path = os.path.join(os.path.dirname(__file__), 'export_html.py')
        result = subprocess.run([
            'python3', script_path, 
            json_file_path, 
            temp_html.name
        ], capture_output=True, text=True)
        
        if result.returncode != 0:
            return jsonify({'error': f'Export failed: {result.stderr}'}), 500
        
        # è¿”å›HTMLæ–‡ä»¶
        response = make_response(send_file(
            temp_html.name,
            as_attachment=True,
            download_name=f'novochoice-analysis-{report_id}.html',
            mimetype='text/html'
        ))
        
        return response
        
    except Exception as e:
        return jsonify({'error': f'Failed to export HTML: {str(e)}'}), 500

@app.route('/reports/<report_id>/export', methods=['GET'])
def export_report(report_id):
    """å¯¼å‡ºæŒ‡å®šæŠ¥å‘Šçš„å®Œæ•´æ•°æ®"""
    try:
        # éªŒè¯æŠ¥å‘ŠIDæ ¼å¼
        if not report_id.startswith('analysis_results_'):
            return jsonify({'error': 'Invalid report ID format'}), 400
        
        # æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨
        if not os.path.exists(report_id):
            return jsonify({'error': 'Report not found'}), 404
        
        # æ”¶é›†æ‰€æœ‰JSONæ–‡ä»¶çš„æ•°æ®
        export_data = {
            'reportId': report_id,
            'exportTime': datetime.now().isoformat(),
            'analysisResults': {}
        }
        
        # è¯»å–æ‰€æœ‰åˆ†æç»“æœæ–‡ä»¶
        analysis_files = [
            'product_type.json',
            'consumer_profile.json',
            'consumer_motivation.json', 
            'consumer_scenario.json',
            'consumer_love.json',
            'star_rating_root_cause.json',
            'unmet_needs.json',
            'opportunity.json',
            'competitor.json'
        ]
        
        for filename in analysis_files:
            filepath = os.path.join(report_id, filename)
            if os.path.exists(filepath):
                try:
                    with open(filepath, 'r', encoding='utf-8') as f:
                        file_data = json.load(f)
                    
                    # æ£€æŸ¥æ˜¯å¦åŒ…å«é”™è¯¯
                    if 'error' not in file_data:
                        module_name = filename.replace('.json', '')
                        export_data['analysisResults'][module_name] = file_data
                        
                except Exception as e:
                    print(f"Warning: Failed to read {filename}: {e}")
        
        # æ·»åŠ å…ƒæ•°æ®
        if os.path.exists(os.path.join(report_id, 'metadata.json')):
            try:
                with open(os.path.join(report_id, 'metadata.json'), 'r', encoding='utf-8') as f:
                    metadata = json.load(f)
                export_data['metadata'] = metadata
            except:
                pass
        
        # è¿”å›JSONæ–‡ä»¶ä¸‹è½½
        response = make_response(json.dumps(export_data, ensure_ascii=False, indent=2))
        response.headers['Content-Type'] = 'application/json; charset=utf-8'
        response.headers['Content-Disposition'] = f'attachment; filename="{report_id}_export.json"'
        
        print(f"âœ… Exported report: {report_id}")
        return response
        
    except Exception as e:
        print(f"âŒ Error exporting report {report_id}: {e}")
        return jsonify({'error': f'Failed to export report: {str(e)}'}), 500

@app.route('/reports', methods=['GET'])
def get_reports():
    """è·å–å†å²æŠ¥å‘Šåˆ—è¡¨"""
    try:
        import glob
        import os
        from datetime import datetime
        
        # è·å–æ‰€æœ‰åˆ†æç»“æœç›®å½•
        result_dirs = glob.glob('result/analysis_results_*')
        result_dirs.sort(reverse=True)  # æŒ‰æ—¶é—´å€’åº
        
        reports = []
        
        for dir_name in result_dirs:
            try:
                # ä»ç›®å½•åæå–æ—¶é—´æˆ³
                timestamp_str = dir_name.replace('result/analysis_results_', '')
                
                # è§£ææ—¶é—´æˆ³
                try:
                    dt = datetime.strptime(timestamp_str, '%Y%m%d_%H%M%S')
                    timestamp = dt.isoformat() + 'Z'
                except:
                    timestamp = datetime.now().isoformat() + 'Z'
                
                # æ£€æŸ¥ç›®å½•ä¸­çš„æ–‡ä»¶
                required_files = [
                    'consumer_profile.json',
                    'consumer_motivation.json', 
                    'consumer_scenario.json',
                    'consumer_love.json',
                    'star_rating_root_cause.json',
                    'unmet_needs.json',
                    'opportunity.json'
                ]
                
                # æ£€æŸ¥æ–‡ä»¶å®Œæ•´æ€§
                complete_files = 0
                has_competitor = False
                
                for filename in required_files:
                    filepath = os.path.join(dir_name, filename)
                    if os.path.exists(filepath):
                        try:
                            with open(filepath, 'r', encoding='utf-8') as f:
                                data = json.load(f)
                            if 'error' not in data:
                                complete_files += 1
                        except:
                            pass
                
                # æ£€æŸ¥ç«å“æ•°æ®
                competitor_file = os.path.join(dir_name, 'competitor.json')
                if os.path.exists(competitor_file):
                    try:
                        with open(competitor_file, 'r', encoding='utf-8') as f:
                            competitor_data = json.load(f)
                        if 'error' not in competitor_data and competitor_data:
                            has_competitor = True
                    except:
                        pass
                
                # ç¡®å®šçŠ¶æ€
                if complete_files >= 6:  # è‡³å°‘6ä¸ªæ ¸å¿ƒæ–‡ä»¶å®Œæ•´
                    status = 'completed'
                elif complete_files > 0:
                    status = 'partial'
                else:
                    status = 'failed'
                
                report = {
                    'id': dir_name,
                    'timestamp': timestamp,
                    'category': 'Webcams',  # é»˜è®¤ç±»åˆ«ï¼Œå¯ä»¥ä»æ–‡ä»¶ä¸­è¯»å–
                    'status': status,
                    'hasCompetitorData': has_competitor,
                    'completedModules': complete_files,
                    'totalModules': len(required_files),
                    'fileInfo': {
                        'ownBrandFile': 'Customer ASIN Reviews.csv',
                        'competitorFile': 'Competitor ASIN Reviews.csv' if has_competitor else None
                    }
                }
                
                reports.append(report)
                
            except Exception as e:
                print(f"Error processing directory {dir_name}: {e}")
                continue
        
        return jsonify({'reports': reports})
        
    except Exception as e:
        print(f"Error getting reports: {e}")
        return jsonify({'reports': []})

@app.route('/report/<path:report_id>', methods=['GET'])
def get_report(report_id):
    """è·å–ç‰¹å®šæŠ¥å‘Š"""
    try:
        print(f"Loading report: {report_id}")
        
        # ç¡®ä¿report_idæ˜¯å®‰å…¨çš„è·¯å¾„
        if not report_id.startswith('result/analysis_results_'):
            return jsonify({'error': 'Invalid report ID'}), 400
        
        # æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨
        if not os.path.exists(report_id):
            return jsonify({'error': 'Report not found'}), 404
        
        # åŠ è½½åˆ†æç»“æœ
        raw_results = {}
        
        # å®šä¹‰éœ€è¦åŠ è½½çš„æ–‡ä»¶
        required_files = [
            'consumer_profile.json', 'consumer_motivation.json', 'consumer_scenario.json',
            'consumer_love.json', 'unmet_needs.json', 'opportunity.json',
            'star_rating_root_cause.json', 'product_type.json'
        ]
        
        # åŠ è½½æ¯ä¸ªæ–‡ä»¶
        for filename in required_files:
            file_path = os.path.join(report_id, filename)
            if os.path.exists(file_path):
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        content = json.load(f)
                        # ç§»é™¤.jsonåç¼€ä½œä¸ºkey
                        key = filename.replace('.json', '')
                        raw_results[key] = content
                except Exception as e:
                    print(f"Error loading {filename}: {e}")
                    raw_results[filename.replace('.json', '')] = {'error': f'Failed to load: {str(e)}'}
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ç«å“æ•°æ®
        competitor_file = os.path.join(report_id, 'competitor.json')
        has_competitor = False
        if os.path.exists(competitor_file):
            try:
                with open(competitor_file, 'r', encoding='utf-8') as f:
                    raw_results['competitor'] = json.load(f)
                    has_competitor = True
            except Exception as e:
                print(f"Error loading competitor data: {e}")
                raw_results['competitor'] = {'error': f'Failed to load: {str(e)}'}
        
        # è½¬æ¢ä¸ºå‰ç«¯æœŸæœ›çš„æ ¼å¼
        formatted_results = {
            'id': report_id,
            'timestamp': os.path.basename(report_id).replace('analysis_results_', '').replace('_', 'T') + 'Z',
            'targetCategory': raw_results.get('product_type', {}).get('product_category_profile', {}).get('category_name', 'Unknown'),
            'hasCompetitorData': has_competitor,
            'ownBrandAnalysis': {
                'userInsights': raw_results.get('consumer_profile', {}),
                'userMotivation': raw_results.get('consumer_motivation', {}),
                'userScenario': raw_results.get('consumer_scenario', {}),
                'userFeedback': {
                    'consumerLove': raw_results.get('consumer_love', {}),
                    'starRating': raw_results.get('star_rating_root_cause', {})
                },
                'unmetNeeds': raw_results.get('unmet_needs', {}),
                'opportunities': raw_results.get('opportunity', {}),
                'productType': raw_results.get('product_type', {})
            }
        }
        
        # å¦‚æœæœ‰ç«å“æ•°æ®ï¼Œæ·»åŠ åˆ°ç»“æœä¸­
        if has_competitor:
            formatted_results['competitor'] = raw_results.get('competitor', {})
        
        print(f"Successfully loaded report with formatted structure")
        return jsonify(formatted_results)
        
    except Exception as e:
        print(f"Error loading report {report_id}: {e}")
        return jsonify({'error': f'Failed to load report: {str(e)}'}), 500

def load_demo_results():
    """ä»result/demoresultæ–‡ä»¶å¤¹åŠ è½½demoæ•°æ®"""
    try:
        demo_dir = 'result/demoresult'
        if not os.path.exists(demo_dir):
            raise Exception("Demo results directory not found")
        
        print(f"Loading demo results from: {demo_dir}")
        
        # è¯»å–demoæ–‡ä»¶
        results = {}
        
        required_files = [
            'consumer_profile.json', 'consumer_motivation.json', 'consumer_scenario.json',
            'consumer_love.json', 'star_rating_root_cause.json', 'unmet_needs.json',
            'opportunity.json', 'competitor.json', 'product_type.json'
        ]
        
        file_mapping = {
            'consumer_profile.json': 'consumer_profile',
            'consumer_motivation.json': 'consumer_motivation', 
            'consumer_scenario.json': 'consumer_scenario',
            'consumer_love.json': 'consumer_love',
            'star_rating_root_cause.json': 'star_rating_root_cause',
            'unmet_needs.json': 'unmet_needs',
            'opportunity.json': 'opportunity',
            'competitor.json': 'competitor',
            'product_type.json': 'product_type'
        }
        
        for filename in required_files:
            filepath = os.path.join(demo_dir, filename)
            key = file_mapping[filename]
            try:
                with open(filepath, 'r', encoding='utf-8') as f:
                    results[key] = json.load(f)
                    print(f"âœ… Loaded demo {filename}: {len(str(results[key]))} characters")
            except Exception as e:
                print(f"âŒ Error loading demo {filename}: {e}")
                results[key] = {}
        
        # è¯»å–demo metadata
        demo_metadata = {}
        metadata_path = os.path.join(demo_dir, 'metadata.json')
        if os.path.exists(metadata_path):
            try:
                with open(metadata_path, 'r', encoding='utf-8') as f:
                    demo_metadata = json.load(f)
                print(f"âœ… Loaded demo metadata")
            except Exception as e:
                print(f"âŒ Error loading demo metadata: {e}")
        
        # æ ¼å¼åŒ–ä¸ºå‰ç«¯æœŸæœ›çš„ç»“æ„
        formatted_result = {
            'id': demo_metadata.get('id', 'demo-analysis'),
            'timestamp': demo_metadata.get('timestamp', datetime.now().isoformat()),
            'hasCompetitorData': demo_metadata.get('hasCompetitorData', bool(results.get('competitor', {}))),
            'targetCategory': demo_metadata.get('targetCategory', 'Webcams'),
            'ownBrandAnalysis': {
                'userInsights': results.get('consumer_profile', {}),
                'userMotivation': results.get('consumer_motivation', {}),
                'userScenario': results.get('consumer_scenario', {}),
                'userFeedback': {
                    'consumerLove': results.get('consumer_love', {}),
                    'starRating': results.get('star_rating_root_cause', {})
                },
                'unmetNeeds': results.get('unmet_needs', {}),
                'opportunities': results.get('opportunity', {})
            },
            'competitorAnalysis': format_competitor_analysis(results.get('competitor', {}))
        }
        
        print(f"âœ… Demo results loaded with {len([k for k, v in results.items() if v])} modules")
        return formatted_result
        
    except Exception as e:
        print(f"âŒ Error loading demo results: {str(e)}")
        # å¦‚æœè¿demoæ•°æ®éƒ½åŠ è½½å¤±è´¥ï¼Œè¿”å›åŸºæœ¬é”™è¯¯ç»“æ„
        return {
            'id': 'demo-analysis',
            'timestamp': datetime.now().isoformat(),
            'hasCompetitorData': False,
            'targetCategory': 'Webcams',
            'error': f'Failed to load demo data: {str(e)}'
        }

if __name__ == '__main__':
    print("ğŸš€ Starting Novochoice AI API Server...")
    print("ğŸ“Š Server will run at: http://localhost:8000")
    print("ğŸ”— Frontend should connect to: http://localhost:8000")
    print("ğŸ’¡ Real-time analysis progress tracking enabled!")
    
    app.run(host='0.0.0.0', port=8000, debug=True)
